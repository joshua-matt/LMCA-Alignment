# LMCA-Alignment
LMCA stands for *Language Model Cognitive Architecture* (see [here](https://www.lesswrong.com/posts/ogHr8SvGqg9pW5wsT/capabilities-and-alignment-of-llm-cognitive-architectures) for more info). 
Examples of LMCA's include [AutoGPT](https://github.com/Significant-Gravitas/Auto-GPT), [ReAct](https://react-lm.github.io/), and [Voyager](https://voyager.minedojo.org/). This repository contains code
for empirical experiments on the alignment properties of these "agentized LLM's", including an implementation of an LMCA in the [Keys and Chests](https://www.alignmentforum.org/posts/AFdRGfYDWQqmkdhFq) environment.
